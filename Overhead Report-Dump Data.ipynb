{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ad9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load source data\n",
    "file_path = r\"C:\\Users\\141823\\OneDrive - Etex Group\\Desktop\\Etex AU - Finance - Finance\\19.Business Systems\\Overhead Report\\Dump Data Automation\\Overhead Report-SAP Download.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "mapping_path = r\"Y:\\Admin - General\\Finance\\Monthly Accounts\\2025\\Dump Data Automation\\COAS.xlsx\"\n",
    "\n",
    "df_mapping = pd.read_excel(mapping_path)\n",
    "df_mapping=df_mapping[['Order', 'Description', 'Responsible CCtr' ]]\n",
    "\n",
    "#Read IPT to replace cost center that contains 'IPT' with Fright Brand\n",
    "temp_path=r\"Y:\\Admin - General\\Finance\\Monthly Accounts\\2025\\Dump Data Automation\\Overhead Report-Dump Data Template.xlsx\"\n",
    "df_IPT1=pd.read_excel(temp_path, sheet_name='IPT Mapping1')\n",
    "df_IPT2=pd.read_excel(temp_path, sheet_name='IPT Mapping2')\n",
    "\n",
    "# Keep only unique Order mappings\n",
    "df_mapping = df_mapping.drop_duplicates(subset='Order')\n",
    "\n",
    "#create 'Ori Cost Center' to keep orginial cost center info for reference\n",
    "df['Ori Cost Center']=df['Cost Center']\n",
    "\n",
    "# Merge on Order\n",
    "df_final = df.merge(df_mapping, on='Order', how='left')\n",
    "\n",
    "# Fill missing Cost Center from Responsible CCtr, Fill Blank Text column with Description\n",
    "if 'Responsible CCtr' in df_final.columns:\n",
    "    df_final['Cost Center'] = df_final['Cost Center'].fillna(df_final['Responsible CCtr'])\n",
    "    df_final['Text']=df_final['Text'].fillna(df_final['Description'])\n",
    "    df_final.drop(columns='Responsible CCtr', inplace=True, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09dc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------Replace IPT-----------------------------------------\n",
    "# Merge with df_IPT1\n",
    "df_final = df_final.merge(df_IPT1, on=['G/L Account','Cost Center'], how='left')\n",
    "\n",
    "# Step 1: Define the 2 G/L Accounts of interest\n",
    "gl_accounts = ['6142000010', '6142000060']\n",
    "\n",
    "# Step 2: Convert 'G/L Account' to string (just in case it's numeric)\n",
    "df_final['G/L Account'] = df_final['G/L Account'].astype(str)\n",
    "df_final['Cost Center'] = df_final['Cost Center'].astype(str)\n",
    "# Ensure consistent string types across all dataframes\n",
    "df_IPT1['G/L Account'] = df_IPT1['G/L Account'].astype(str)\n",
    "df_IPT1['Cost Center'] = df_IPT1['Cost Center'].astype(str)\n",
    "df_IPT2['G/L Account'] = df_IPT2['G/L Account'].astype(str)\n",
    "df_final['Plant'] = pd.to_numeric(df_final['Plant'], errors='coerce').astype('Int64')\n",
    "df_IPT2['Plant'] = pd.to_numeric(df_IPT2['Plant'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Step 3: Apply your rules\n",
    "# Scenario 1 & 2: If G/L Account is in target and Cost Center contains 'IPT1' → replace with IPT column, based on Cost Center\n",
    "df_final.loc[\n",
    "    (df_final['G/L Account'].isin(gl_accounts)) &\n",
    "    (df_final['Cost Center'].astype(str).str.contains('IPT', na=False)),\n",
    "    'Cost Center'\n",
    "] = df_final['IPT1']\n",
    "\n",
    "# Convert string 'nan' to real NaN\n",
    "df_final['Cost Center'] = df_final['Cost Center'].replace('nan', pd.NA)\n",
    "df_final['Cost Center'] = df_final['Cost Center'].replace(['', 'nan'], pd.NA)\n",
    "\n",
    "# Scenario 3: If Cost Center is blank or nan and G/L Account is in target → fill with IPT2 column, based on Plant\n",
    "#First merge with IPT2\n",
    "# Merge on 'G/L Account' and 'Plant'\n",
    "df_final = df_final.merge(df_IPT2, on=['G/L Account', 'Plant'], how='left')\n",
    "\n",
    "# Replace only rows where Cost Center is blank AND G/L Account is in target list\n",
    "mask = (\n",
    "    df_final['G/L Account'].isin(gl_accounts) &\n",
    "    df_final['Cost Center'].isna()\n",
    ")\n",
    "\n",
    "df_final.loc[mask, 'Cost Center'] = df_final.loc[mask, 'IPT2']\n",
    "\n",
    "# Scenario 4: If Cost Center and Plant are both blank → fill with 'Freight Siniat'\n",
    "df_final.loc[\n",
    "    (df_final['G/L Account'].isin(gl_accounts)) & df_final['Cost Center'].isna() & df_final['Plant'].isna(),\n",
    "    'Cost Center'\n",
    "] = 'Freight Siniat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2407a790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed successfully.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------Remove error document rows and pairing rows---------------------\n",
    "# Step 1: Read the list of document numbers to check\n",
    "df_doc2remove = pd.read_excel(temp_path, sheet_name='Remove Doc')\n",
    "doc_nums = df_doc2remove['Document Number'].dropna().unique()\n",
    "\n",
    "# Step 2: Filter df_final to get only the relevant rows\n",
    "rows_to_check = df_final[df_final['Document Number'].isin(doc_nums)]\n",
    "\n",
    "# Step 3: Calculate total amount for those document numbers\n",
    "total_amount = rows_to_check['Amount in Local Currency'].sum()\n",
    "\n",
    "# Step 4: Remove the rows only if the total adds up to zero\n",
    "if abs(total_amount) < 1e-6:  # small threshold to account for rounding\n",
    "    df_final = df_final[~df_final['Document Number'].isin(doc_nums)]\n",
    "    print(\"Rows removed successfully.\")\n",
    "else:\n",
    "    print(\"Total documents do not sum to zero — no rows removed.\")\n",
    "\n",
    "# create 'Change' column\n",
    "df_final['Change'] = np.where(\n",
    "    df_final['Ori Cost Center']!= df_final['Cost Center'], \n",
    "    df_final['Cost Center'], \n",
    "    ''\n",
    ")\n",
    "\n",
    "# Select columns for export\n",
    "df_final = df_final[[ \n",
    "    'Document Number', 'Document Date', 'Posting Date', 'Entry Date', 'User Name',\n",
    "    'Cost Center', 'G/L Account', 'Tax Code', 'Amount in Local Currency', 'Text',\n",
    "    'Order', 'Assignment', 'Trading Partner No.', 'WBS Element', 'Document Currency', \n",
    "    'Amount in Doc. Curr.','Plant','Purchasing Document','Supplier','Ori Cost Center','Change'\n",
    "]]\n",
    "\n",
    "# Format dates to dd/mm/yyyy\n",
    "for date_col in ['Document Date', 'Posting Date', 'Entry Date']:\n",
    "    df_final[date_col] = pd.to_datetime(df_final[date_col], errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728ded09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\141823\\AppData\\Local\\Temp\\ipykernel_27236\\1863714481.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_final = df_final.applymap(lambda x: None if pd.isna(x) else x)\n"
     ]
    }
   ],
   "source": [
    "# Load the workbook\n",
    "from openpyxl import load_workbook\n",
    "wb = load_workbook(temp_path)\n",
    "ws = wb[\"SAP Data Final\"]\n",
    "\n",
    "# Clear old data but keep headers\n",
    "ws.delete_rows(2, ws.max_row)  # Deletes from row 2 downwards (keeps headers)\n",
    "\n",
    "# Replace <NA> with None for Excel compatibility\n",
    "df_final = df_final.applymap(lambda x: None if pd.isna(x) else x)\n",
    "\n",
    "# Write updated DataFrame to \"SAP Data Final\" (including headers)\n",
    "for c_idx, column in enumerate(df_final.columns, start=1):\n",
    "    ws.cell(row=1, column=c_idx, value=column)  # Write column headers\n",
    "\n",
    "for r_idx, row in enumerate(df_final.itertuples(index=False), start=2):  # Start from row 2 (below headers)\n",
    "    for c_idx, value in enumerate(row, start=1):\n",
    "        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for col in ws.columns:\n",
    "    max_length = 0\n",
    "    col_letter = col[0].column_letter  # Get column letter (A, B, C, etc.)\n",
    "    for cell in col:\n",
    "        try:\n",
    "            if cell.value:\n",
    "                max_length = max(max_length, len(str(cell.value)))\n",
    "        except:\n",
    "            pass\n",
    "    ws.column_dimensions[col_letter].width = max_length + 2  # Add padding\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(temp_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
